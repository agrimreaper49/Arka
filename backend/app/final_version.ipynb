{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "!pip install transformers torch flask flask-ngrok\n",
        "!pip install pyngrok pandas sentence-transformers langchain\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssVr5XsuAxLF",
        "outputId": "b614d4e9-184b-49b2-92eb-4a4146f4c491"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-gwsvwh6t/unsloth_d004b21605414671b8004364b68ce2f7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-gwsvwh6t/unsloth_d004b21605414671b8004364b68ce2f7\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 73, in resolve\n",
            "    collected = self.factory.collect_root_requirements(root_reqs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 491, in collect_root_requirements\n",
            "    req = self._make_requirement_from_install_req(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 453, in _make_requirement_from_install_req\n",
            "    cand = self._make_candidate_from_link(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 206, in _make_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 293, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 156, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 225, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 304, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 516, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 587, in _prepare_linked_requirement\n",
            "    local_file = unpack_url(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 155, in unpack_url\n",
            "    unpack_vcs_link(link, location, verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 78, in unpack_vcs_link\n",
            "    vcs_backend.unpack(location, url=hide_url(link.url), verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/vcs/versioncontrol.py\", line 608, in unpack\n",
            "    self.obtain(location, url=url, verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/vcs/versioncontrol.py\", line 521, in obtain\n",
            "    self.fetch_new(dest, url, rev_options, verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/vcs/git.py\", line 276, in fetch_new\n",
            "    self.run_command(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/vcs/versioncontrol.py\", line 650, in run_command\n",
            "    return call_subprocess(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/subprocess.py\", line 166, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 207, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 396, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 365, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 323, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Collecting xformers<0.0.27\n",
            "  Downloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (222.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.7/222.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl<0.9.0\n",
            "  Downloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft\n",
            "  Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes, xformers, trl, peft\n",
            "Successfully installed bitsandbytes-0.43.1 peft-0.11.1 trl-0.8.6 xformers-0.0.26.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vfP1FzU_gJt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import threading\n",
        "import pandas as pd\n",
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "from unsloth import FastLanguageModel\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain import LangChain\n",
        "from langchain.chains import SimpleChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import LLM\n",
        "\n",
        "app = Flask(__name__)\n",
        "port = \"5000\"\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_name = \"agrimreaper48/first-model\"  # Your model name with LoRA\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=model_name,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit,\n",
        ")\n",
        "\n",
        "FastLanguageModel.for_inference(model)  # Enable native 2x faster inference\n",
        "\n",
        "# Initialize sentence transformer for document embeddings\n",
        "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Load and preprocess player stats CSV\n",
        "df = pd.read_csv('player_stats.csv')\n",
        "\n",
        "def preprocess_player_stats(row):\n",
        "    return (f\"Player {row['PLAYER NAME']} from team {row['PLAYER TEAM']} \"\n",
        "            f\"plays as {row['PLAYER POSITION']} against {row['OPP']}. \"\n",
        "            f\"Status: {row['STATUS']}. \"\n",
        "            f\"Projected points: {row['PROJ']}. \"\n",
        "            f\"Passing stats: {row['PASSING C/A']} completions, {row['PASSING YDS']} yards, \"\n",
        "            f\"{row['PASSING TD']} touchdowns, {row['PASSING INT']} interceptions. \"\n",
        "            f\"Rushing stats: {row['RUSHING CAR']} carries, {row['RUSHING YDS']} yards, \"\n",
        "            f\"{row['RUSHING TD']} touchdowns. \"\n",
        "            f\"Receiving stats: {row['RECEIVING REC']} receptions, {row['RECEIVING YDS']} yards, \"\n",
        "            f\"{row['RECEIVING TD']} touchdowns. \"\n",
        "            f\"Miscellaneous: {row['MISC 2PC']} two-point conversions, {row['MISC FUML']} fumbles, \"\n",
        "            f\"{row['MISC TD']} touchdowns, Total points: {row['TOTAL']}.\")\n",
        "\n",
        "# Create a list of player descriptions\n",
        "player_texts = df.apply(preprocess_player_stats, axis=1).tolist()\n",
        "\n",
        "# Generate embeddings for player stats\n",
        "player_embeddings = sentence_model.encode(player_texts)\n",
        "\n",
        "# Define LangChain components\n",
        "class CustomLLM(LLM):\n",
        "    def __init__(self, model, tokenizer):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def call(self, prompt):\n",
        "        inputs = self.tokenizer([prompt], return_tensors='pt').to('cuda')\n",
        "        outputs = self.model.generate(**inputs, max_new_tokens=64, use_cache=True)\n",
        "        result = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "        return result\n",
        "\n",
        "custom_llm = CustomLLM(model, tokenizer)\n",
        "\n",
        "# Define a simple LangChain chain\n",
        "class PlayerPredictionChain(SimpleChain):\n",
        "    def __init__(self, llm, sentence_model, player_embeddings, player_texts):\n",
        "        super().__init__(llm)\n",
        "        self.sentence_model = sentence_model\n",
        "        self.player_embeddings = player_embeddings\n",
        "        self.player_texts = player_texts\n",
        "\n",
        "    def _call(self, prompt):\n",
        "        query_embedding = self.sentence_model.encode(prompt)\n",
        "        player_similarities = cosine_similarity([query_embedding], self.player_embeddings)\n",
        "        most_similar_player_index = player_similarities.argmax()\n",
        "        most_relevant_player = df.iloc[most_similar_player_index]\n",
        "        return (f\"Based on your query, the most relevant player is {most_relevant_player['PLAYER NAME']} \"\n",
        "                f\"from team {most_relevant_player['PLAYER TEAM']} with {most_relevant_player['TOTAL']} total points.\")\n",
        "\n",
        "player_prediction_chain = PlayerPredictionChain(custom_llm, sentence_model, player_embeddings, player_texts)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.get_json()\n",
        "    instruction = data['instruction']\n",
        "    input_text = data['input']\n",
        "    output_text = data['output']\n",
        "\n",
        "    alpaca_prompt = \"{instruction} {input} {output}\"  # Format the prompt\n",
        "    query = alpaca_prompt.format(instruction=instruction, input=input_text, output=output_text)\n",
        "\n",
        "    # Use LangChain to get prediction\n",
        "    response_text = player_prediction_chain.call(query)\n",
        "\n",
        "    return jsonify({'response': response_text})\n",
        "\n",
        "# Start the Flask server in a new thread\n",
        "def run_server():\n",
        "    app.run(port=int(port), use_reloader=False, debug=True)\n",
        "\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f\"ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{port}\\\"\")\n",
        "\n",
        "threading.Thread(target=run_server).start()\n"
      ]
    }
  ]
}